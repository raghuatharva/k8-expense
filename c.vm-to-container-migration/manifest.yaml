# only target group binding will change ; remaining everything will remain same
# instances ----> to -----> pods
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: expense
  labels:                # This is the label of the replicaset. This is used to identify the replicaset only.
    app: nginx             
    tier: frontend
    project: expense
spec:
  replicas: 3               # Number of pods to be created
  selector:
    matchLabels:         # This should be the label of the pod to which this replicaset will manage          
      app: nginx             
      tier: frontend
      project: expense
  template:
    metadata:
      labels:             # (This is the label of the pod) this label should be same as matchLabels of selector  
        app: nginx             
        tier: frontend
        project: expense
    spec:
      containers:
      - name: frontend
        image: rohanraghu/frontend:v1
        resources:
          requests:
            memory: "64Mi"  #soft limit 64 megabytes
            cpu: "250m"
          limits:
            memory: "128Mi" #hard limit 128 megabytes max.
            cpu: "500m"
        # securityContext:
        #   capabilities:
        #     add: ["NET_BIND_SERVICE"]
---
################################################################################################
      # Why the Capability?

      # On Linux, binding to ports below 1024 (like port 80) requires elevated privileges. Since your Dockerfile sets the user to nginx (a non-root user), nginx doesnâ€™t have permission by default.

      # Adding NET_BIND_SERVICE:
      # The added line in the security context:
      # securityContext:
      #   capabilities:
      #     add:
      #       - NET_BIND_SERVICE

      # This instructs Kubernetes to grant the container the ability to bind to privileged ports. This way, even though nginx runs as the non-root nginx user, it can still bind to port 80.
################################################################################################
kind: Service
apiVersion: v1
metadata:
  name: nginx
  namespace: expense
spec:
  # type: LoadBalancer
  selector:           # This is the label of the pod to which this service will route the traffic
    app: nginx             
    tier: frontend
    project: expense    
  ports:
  - name: nginx-service
    port: 80         # Service Port , this is for other containers to communicate with nginx container
    targetPort: 80   # Container Port
    protocol: TCP
---
################################################################################################
# MIGRATION STEPS:
# 1. Create a deployment for the frontend service
# 2. Create a service for the frontend service -- no load balancer here because we will use existing ALB
# 3. Create a HorizontalPodAutoscaler for the frontend service
# 4. use the same ALB , target group and listener you used for the VM
# 5. Update the target group binding for the service
################################################################################################

#target_group_binding 

apiVersion: elbv2.k8s.aws/v1beta1
kind: TargetGroupBinding
metadata:
  name: frontend
  namespace: expense
spec:
  serviceRef:
    name: nginx
    namespace: expense
  targetGroupARN: arn:aws:elasticloadbalancing:us-west-2:123456789012:targetgroup/frontend/1234567890123456
  targetType: ip #most important part because we are using ip target type in conatiners and not instance